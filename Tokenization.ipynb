{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc03d24e-261c-4185-8baa-092c14f58499",
   "metadata": {},
   "source": [
    "# Creating Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcc6759-491a-4c2a-8f1a-ebf46eb4e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./the-verdict.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5cb2420-df5f-4725-93fd-3788c6d8d72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20479"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515884b3-9f23-4ba1-9fdd-5ebe25ce1a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:99]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276e9d8-a3fe-40a0-ac14-053210536a88",
   "metadata": {},
   "source": [
    "### Splitting using re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bbb8ca2-8f75-488c-94cc-5988da23842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06187091-c11b-40f0-ae40-e1a5a7f5af93",
   "metadata": {},
   "source": [
    "Tokens still have punctuation. \\s seperates tokens based on space encountered. Moreoever, each space in also counted as a token.\n",
    "\n",
    "<strong>Note:</strong> We will not lowercase the text because the capitalization helps LLMs distinguish between proper nouns and common nouns, understand sentence structure, and learn to generate text with proper capitalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f5e4e4-ef76-4eea-8418-bccadfb1d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.split(r'([,.]|\\s)', text)\n",
    "result = [item for item in result if item.strip()] # Removing space tokens\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fac13-d724-442d-974e-1b7142578a02",
   "metadata": {},
   "source": [
    "<strong>Note:</strong> Removing whitespaces reduces memory and computation. However, when training on data sensitive to space such as Python code, we will keep the spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e711d4-f444-42e5-9e0f-8a63a110ecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying to our data\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.split()]\n",
    "len(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27cfcd6-c875-4343-8e88-4ca669870657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08ead45-bf1d-457d-b123-e56f56cc7800",
   "metadata": {},
   "source": [
    "### Creating Token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9578302-0a76-4f3f-a6d9-75173c9aaea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "# Creating list of all unique tokens and sorting them alphabetically to determine vocab size\n",
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c760225-f129-403c-892c-e100ca439c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n"
     ]
    }
   ],
   "source": [
    "# Creating vocab\n",
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i>= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24c10607-1afb-4123-bdbd-65e1783132e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        # Stores the vocabulary as a class attribute for access in the encode and decode methods\n",
    "        self.str_to_int = vocab\n",
    "\n",
    "        # Creates an inverse vocabulary that maps token IDs back to the original text tokens\n",
    "        self.int_to_str = {i:s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text): # Processes input text into token IDs\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.split()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids): # Converts token IDs back into text\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "\n",
    "        # Removes spaces before the specified punctuation\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0715197-eb48-467b-b347-dcd136316abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "       Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e7601fe-205c-4b81-b57b-0e8a0e080e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d00d8e5-50bd-4f07-baa2-98d290533132",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, do you like tea?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mencode(text))\n",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m, in \u001b[0;36mSimpleTokenizerV1.encode\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     10\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m([,.?_!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]|--|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[0;32m     11\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m [item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[1;32m---> 12\u001b[0m ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr_to_int[s] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Hello'"
     ]
    }
   ],
   "source": [
    "text = \"Hello, do you like tea?\"\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7875222e-0a23-485f-80e3-80ddc766155d",
   "metadata": {},
   "source": [
    "<strong>Note:</strong> This problem occured because this word is not part of the voacb we created. To handle unknown words, we will add 2 new tokens - <|unk|> and <|endoftext|>.\n",
    "\n",
    "<|unk|>: we will modify the tokenizer to use this token whenever it encounters an unknown word.<br>\n",
    "<|endoftext|>: To separate two unrelated text source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15c018f1-4faa-442b-ac31-051d33b3fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d42ae38-5fb5-421f-82ae-7b809e548c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0fccfb2-54c8-40cc-ba5e-1cec56e754e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.split()]\n",
    "        # Replaces unknown words by <|unk|> tokens\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb7748a7-62d5-45f7-8b82-dea88d239427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be94a3f6-01ed-4d87-8be0-7188fc63cc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7420f9e4-771c-423b-8304-5f2123f0d46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653b7dd-4b48-4207-a595-d567700479ea",
   "metadata": {},
   "source": [
    "### Byte Pair Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8f37c8c-4271-4bb4-800c-e6a1b2dbe1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\aarus\\anaconda3\\lib\\site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\aarus\\anaconda3\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aarus\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aarus\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aarus\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aarus\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 884.3/884.3 kB 10.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d508106a-3260-461e-91c4-83e1dd56263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6634cfce-b338-4470-bd59-dd78d07bd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc1a4c97-9eb8-49ed-913c-9fb1dd22b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2874da6f-9b5a-490f-8b59-8bfd45228c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e8356-6f63-44b7-81c9-8938195193f2",
   "metadata": {},
   "source": [
    "Original chatgpt has a total vocab size of 50,257, with <|endoftext|> being assigned the largest token id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e877c20-42aa-4dd4-9ec4-6b9b680a007d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing on our dataset\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "len(enc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f63cf-b36d-483f-8804-4b3a288a2ba7",
   "metadata": {},
   "source": [
    "## Creating input-target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90e12b30-65c3-4328-923b-e2ca5208e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05411fb6-7e6d-4f3a-8882-2c0b928c186e",
   "metadata": {},
   "source": [
    "<strong>To create input-target pairs, we create 2 variables, x and y, where x contains the input and y the target, which is input shifted by 1.</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3d78a56-36ab-48d0-ac5d-1b4c88b689a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "# Context size 4 means that the model us trained to look at a sequence of 4 words (or token) \n",
    "# to predict the next word in the seq.\n",
    "# The input x is the first 4 tokens [1, 2, 3, 4] and y is the next 4 tokens [2, 3, 4 5]\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0437637-8eb5-4a37-83a6-82802886ca81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047e6e2-cc57-4b88-b9c4-12ed2fec5de7",
   "metadata": {},
   "source": [
    "Everything left of the arrow (---->) refers to the input an LLM would receive, and the token ID on the right side of the arrow represents the target token ID that the LLM is supposed to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f2846e7-8488-4336-a0a9-0dd68fe3cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944723a-acea-416b-b0fc-4c70e401f292",
   "metadata": {},
   "source": [
    "<strong>Note:</strong> Here each input-target pairs corresponds to 1 prediction task. Since our context window is 4 here, we has 4 prediction tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58c6543-c175-4ea6-bb23-aa9b55a7dfdc",
   "metadata": {},
   "source": [
    "To feed these input-output pairs to an LLM, we need to create a data loader that can return the input-target pairs as Pytorch tensors.\n",
    "\n",
    "Note: BPE encoder performed the tokenization and conversion to token id in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eac8770-f1b2-46f7-b5bb-c135c93d74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcac6027-d268-48d1-be6b-c58e4c74ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_id = tokenizer.encode(text)\n",
    "\n",
    "        # using sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_id) - max_length, stride):\n",
    "            input_chunk = token_id[i:i+max_length]\n",
    "            target_chunk = token_id[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ac11af0-14e5-4601-b096-d1b0cb0e17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(text, batch_size=4, max_length = 256, stride = 128, \n",
    "                         shuffle = True, drop_last = True, num_workers = 0):\n",
    "    # drop_last = True drops the last batch if its shorter than the specified batch size \n",
    "    # to prevent loss spikes during training\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n",
    "\n",
    "    # Checks the __getitem__ class and returns the specified item, in our case the input-target pairs\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52238098-0c4d-4fa5-be63-d764f2675c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464, 1807]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f79a836-34b1-4aa5-a9ee-f617e60d535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc24a1-357a-4e86-84fd-f62cd8a6407b",
   "metadata": {},
   "source": [
    "<strong>Note:</strong> We increase the stride to 4 to utilize the data set fully (we don't skip a single word) but also avoid any overlap between the batches, since more overlap can lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c335e2e-1437-4d36-bb77-b8e2bdeb2ec2",
   "metadata": {},
   "source": [
    "### Creating Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bc668eb-18e5-4547-a70a-332ddc28e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d60f8e2-3261-44ce-becc-2362bb78aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dum = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# Embedding is a simple lookup table that stores embeddings of a fixed dictionary and size\n",
    "# Used to store word embeddings and retrieve them using indices.\n",
    "# Input is list of indices and output is word embeddings.\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26d6a633-700e-4ac9-97f5-efd330d1b702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3374, -0.1778, -0.1690],\n",
       "        [ 0.9178,  1.5810,  1.3010],\n",
       "        [ 1.2753, -0.2010, -0.1606],\n",
       "        [-0.4015,  0.9666, -1.1481],\n",
       "        [-1.1589,  0.3255, -0.6315],\n",
       "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599e707-80b9-420a-a493-43c1412d5e57",
   "metadata": {},
   "source": [
    "These are random values which will be later optimized.<br>\n",
    "Note that the weight matrix has 6 rows and 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ffc95b7-3101-477e-924c-8f5dcb932fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer(torch.tensor([3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e356601-2dd0-4969-b548-cd7d24425e84",
   "metadata": {},
   "source": [
    "It is the same as the 4th row in weight matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ea0a21-ba24-427a-aaaa-250a7156cf55",
   "metadata": {},
   "source": [
    "### Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4156bf9b-2261-40bb-9625-e4ef97ee070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8232edd8-2327-435f-ba9c-57367828d7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "   stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75fa7d14-a13f-4d08-8e38-e977a727a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26949a-fdea-4842-b283-90416583cc74",
   "metadata": {},
   "source": [
    "For each token id, we have created a embedding of size 256. Hence we have the size 8 x 4 x 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "30a25494-325a-4029-a42e-04c617a95aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, out_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "pos_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd3554-f342-40f4-8ac6-5b2008702bb3",
   "metadata": {},
   "source": [
    "The context_length is a variable that represents the supported input size of the LLM. Here, we choose it similar to the maximum length of the input text. In practice, input text can be longer than the supported context length, in which case we have to truncate the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f728955-690f-4b2e-8b06-9cf060e86f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "input_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2933ad8-872d-4b15-b6df-e2bc386fdb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
